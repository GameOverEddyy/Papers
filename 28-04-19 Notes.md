# A Few Useful Things to Know about Machine Learning (Notes)

## Terminology:

* __Classifier__ - A system that inputs a vector of discrete/continuous _feature values_ and outputs a single discrete value called a _class_ or _category_
* __Learner__ - A learner inputs a _training set_ of _examples_ and outputs a _classifier_. 
* __Hypothesis Space__ - The set of _classifiers_ a _learner_ can possibly learn. Anything outside the _hypothesis space_ cannot be learned. 
* __Objective Function/Scoring Function__ - Used to distinguish good classifiers from bad ones. E.g, mean average errors.
* __Overfitting__ - A model that models the training data too well, including details and noise, such that it negatively impacts the model on new data. 
* __Underfitting__ - A model that can neither model the training data nor new data. 
* __Reguarization Term__ - A method to combat overfitting. Penalizes classifiers with with more structure favoring smaller ones with less room to overfit. 
* __Model Ensembles__ - Combining many variations of learners. 
* __Bagging__ - A method of generating random variations of the training set by resampling, learn a classifier on each, and combine the results by voting. 
* __Boosting__ - Training examples have weights and these are varied so that each new classifier focuses on the examples the previous ones tended to get wrong. In _stacking_, the outputs of individual classifiers become the inputs of a "higher-level" learner that figures out how best to combine them. 

## Learning = Representation + Evaluation + Optimization



## Curse of Dimensionality

## Theoretical Guarantees

